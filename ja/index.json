[{"authors":["admin"],"categories":null,"content":"東京大学大学院情報理工学系研究科修士課程在籍. 現在の関心は「機械学習モデルに対する攻撃」でとりわけ, \u0026ldquo;Model Extraction\u0026quot;と呼ばれる機械学習の「逆問題」に興味を持っている. プラクティカルな実装も好きで, あらゆる課題をあらゆるデータから解決することを目標としている.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"ja","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://d-dof.github.io/ja/author/%E6%A3%AE-%E9%9B%84%E4%BA%BA-/-yuto-mori/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/ja/author/%E6%A3%AE-%E9%9B%84%E4%BA%BA-/-yuto-mori/","section":"authors","summary":"東京大学大学院情報理工学系研究科修士課程在籍. 現在の関心は「機械学習モデルに対する攻撃」でとりわけ, \u0026ldquo;Model Extraction\u0026quot;と呼ばれる機械学習の「逆問題」に興味を持っている. プラクティカルな実装も好きで, あらゆる課題をあらゆるデータから解決することを目標としている.","tags":null,"title":"森 雄人 / Yuto Mori","type":"authors"},{"authors":[],"categories":[],"content":"自分の備忘録も兼ねて, カジュアルに機械学習のちょっとした Tips をまとめるシリーズを始めてみたいと思います. 第一弾はカーネルモデルに対する近似手法について.\nカーネルモデルを近似する方法としていくつかの方法 (Nyström近似など) がありますが, そのうちランダムな基底 (特徴) を用いて近似する手法を Random Feature といいます. これは [Rahimi and Recht, NeurIPS, 2008]によって提案された手法で, アイディアはシンプルですが非常に面白いです.\nBochner の定理と Random Feature  $\\mathbb{R}^d$ 上の連続な平行移動不変カーネル $k(x, y) = k(x - y)$ が正定値であることの必要十分条件は $k(\\delta)$ が非負測度のフーリエ変換となることである.\n これは Bochner の定理と呼ばれるものです. この結果から具体的な表式として, 平行移動不変なカーネル関数はある確率分布 $p(\\omega)$ を用いて次のように表現することができます. \\begin{align} k(x-y) \u0026amp;= \\int_{\\mathbb{R}^d} p(\\omega) e^{i \\omega^{\\top}(x-y)} d \\omega\\\\\n\u0026amp;= \\mathbb{E} [e^{i \\omega^{\\top}x} \\overline{e^{i \\omega^{\\top} y}}] \\end{align}\nここでさらに, 実用上実数値カーネルを考えれば十分であることに注意し, 加法定理を用いて整理すると \\begin{align} k(x-y) \u0026amp;= \\mathbb{E}[\\sqrt{2} \\cos (\\omega^{\\top}x + b) \\sqrt{2} \\cos (\\omega^{\\top}y + b)]\\\\\n\u0026amp;\\approx \\frac{1}{D} \\sum_{j=1}^{D} \\sqrt{2} \\cos (\\omega^{\\top}_{j} x + b_j) \\sqrt{2} \\cos (\\omega^{\\top}_{j} y + b_j) \\end{align} と表すことができます. なおここで $\\omega, \\omega_j \\sim p(\\omega), b, b_j \\sim U[0, 2\\pi]$ です. このとき, 上の期待値の不偏推定量による近似をシンプルに考えています.\nさて, ここで\n\\begin{align} z(x) = \\begin{pmatrix} \\sqrt{\\frac{2}{D}} \\cos(\\omega_1^{\\top} x + b_1)\\\\\n\\vdots \\\\\n\\sqrt{\\frac{2}{D}} \\cos(\\omega_D^{\\top} x + b_D) \\end{pmatrix} \\end{align} という関数を考えると, ランダムに $x$ を $\\mathbb{R}^D$ 上へ埋め込んでいる関数になっており, 先ほどの推定量は $z(x)^{\\top} z(y)$ と書くことができます. この $z(x)$ こそが Random Features であって, 「(一般には無限次元空間への写像となりがちな) 特徴写像をランダムに (低次元空間への写像として) 近似したもの」と見ることもできるというカラクリです. 非常に面白いですね.\nReferences   Ali Rahimi and Ben Recht. Random features for large-scale kernel machines. Advances in Neural Information Processing Systems, 2008.  Wikipedia: Bochner\u0026rsquo;s theorem http://gregorygundersen.com/blog/2019/12/23/random-fourier-features/  ","date":1601265160,"expirydate":-62135596800,"kind":"page","lang":"ja","lastmod":1601265160,"objectID":"7e79f61a467e89be871621dfb6b749f9","permalink":"https://d-dof.github.io/ja/post/random-feature/","publishdate":"2020-09-28T12:52:40+09:00","relpermalink":"/ja/post/random-feature/","section":"post","summary":"Random Feature についてのまとめ","tags":["Kernel","ML-Tips","Random Feature","Famous Topic"],"title":"カーネルモデルを近似する手法: Random Feature","type":"post"},{"authors":[],"categories":[],"content":"このポートフォリオサイトを開設しました.\n","date":1587791238,"expirydate":-62135596800,"kind":"page","lang":"ja","lastmod":1587791238,"objectID":"b3217fe2c9870a6f194a145697561e25","permalink":"https://d-dof.github.io/ja/post/1-intro/","publishdate":"2020-04-25T14:07:18+09:00","relpermalink":"/ja/post/1-intro/","section":"post","summary":"このポートフォリオサイトを開設しました.","tags":[],"title":"開設 !!!","type":"post"}]