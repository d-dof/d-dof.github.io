<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts | D_dof</title>
    <link>https://d-dof.github.io/post/</link>
      <atom:link href="https://d-dof.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    <description>Posts</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>Â©Yuto Mori 2021</copyright><lastBuildDate>Sat, 22 May 2021 20:43:18 +0900</lastBuildDate>
    <image>
      <url>https://d-dof.github.io/images/icon_hue41c9815bcb191b17ee2aa1053a33549_67626_512x512_fill_lanczos_center_2.png</url>
      <title>Posts</title>
      <link>https://d-dof.github.io/post/</link>
    </image>
    
    <item>
      <title>BODAME: Bilevel Optimization for Defense Against Model Extraction</title>
      <link>https://d-dof.github.io/post/bodame/</link>
      <pubDate>Sat, 22 May 2021 20:43:18 +0900</pubDate>
      <guid>https://d-dof.github.io/post/bodame/</guid>
      <description>&lt;p&gt;We have published our paper in arXiv.&lt;/p&gt;
&lt;p&gt;Yuto Mori, Atsushi Nitanda, and Akiko Takeda. BODAME: Bilevel Optimization for Defense Against Model Extraction. 2021. 
&lt;a href=&#34;https://arxiv.org/abs/2103.06797&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;[arXiv]&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;As the title suggests, we formulate the problem of defending machine learning models from model extraction attacks as a bilevel optimization problem, and propose methods to solve.&lt;/p&gt;
&lt;p&gt;In addition, I have published some of the survey materials that I had compiled when I was a master&amp;rsquo;s student.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;https://github.com/d-dof/survey_in_m2/blob/master/survey_in_m2.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PDF&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://github.com/d-dof/survey_in_m2&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub repository&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It&amp;rsquo;s a survey that I&amp;rsquo;ve been compiling as a diary as we move into the coronavirus crisis.
It mainly summarizes topics related to model extraction attacks, but also includes some abstracts of papers on the following topics.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Active Learning&lt;/li&gt;
&lt;li&gt;Semi-supervised Learning&lt;/li&gt;
&lt;li&gt;Kernel Methods&lt;/li&gt;
&lt;li&gt;Machine Teaching&lt;/li&gt;
&lt;li&gt;Gaussian Process&lt;/li&gt;
&lt;li&gt;Poisoning&lt;/li&gt;
&lt;li&gt;Meta-Learning&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Random Feature</title>
      <link>https://d-dof.github.io/post/random-feature/</link>
      <pubDate>Mon, 28 Sep 2020 13:01:34 +0900</pubDate>
      <guid>https://d-dof.github.io/post/random-feature/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Open !!!</title>
      <link>https://d-dof.github.io/post/1-intro/</link>
      <pubDate>Sat, 25 Apr 2020 12:37:38 +0900</pubDate>
      <guid>https://d-dof.github.io/post/1-intro/</guid>
      <description>&lt;p&gt;This portfolio site has been deployed !!&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
